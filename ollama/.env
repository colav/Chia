# Ollama Configuration
OLLAMA_VERSION=latest
OLLAMA_PORT=11434

# Performance Settings
# Number of models to run in parallel (increase for multiple concurrent requests)
OLLAMA_NUM_PARALLEL=1

# Maximum number of models to keep loaded in memory
OLLAMA_MAX_LOADED_MODELS=1

# How long to keep models loaded in memory (e.g., 5m, 1h, 0 = keep forever)
OLLAMA_KEEP_ALIVE=5m

# GPU Configuration
# Set GPU_COUNT > 0 to enable NVIDIA GPU support
GPU_DRIVER=nvidia
GPU_COUNT=1

# Example configurations:
# -----------------------------------------------------
# Development (CPU only):
#   GPU_COUNT=0
#   OLLAMA_NUM_PARALLEL=1
#   OLLAMA_MAX_LOADED_MODELS=1
#
# Production (Single GPU):
#   GPU_COUNT=1
#   OLLAMA_NUM_PARALLEL=2
#   OLLAMA_MAX_LOADED_MODELS=2
#
# Production (Multi-GPU):
#   GPU_COUNT=all
#   OLLAMA_NUM_PARALLEL=4
#   OLLAMA_MAX_LOADED_MODELS=3
# -----------------------------------------------------

